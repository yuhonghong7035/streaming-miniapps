{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MASS / MASA Kinesis - Lambda\n",
    "\n",
    "In the first step we need to import all required packages and modules into the Python Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pilot-Compute Description is a simple key/value style description of the cluster environment that should be started. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T17:59:21.386383Z",
     "start_time": "2017-12-28T17:59:21.364643Z"
    }
   },
   "outputs": [],
   "source": [
    "# System Libraries\n",
    "import sys, os\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "import datetime\n",
    "## logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "logging.getLogger(\"py4j\").setLevel(logging.ERROR)\n",
    " \n",
    "import pyspark\n",
    "import os\n",
    "import boto3\n",
    "boto3.setup_default_session(profile_name='dev')\n",
    "import time\n",
    "import mass.kafka\n",
    "    \n",
    "# Pilot-Streaming\n",
    "import pilot.streaming\n",
    "sys.modules['pilot.streaming']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Kinesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start Spark Cluster and Wait for Startup Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-28T18:00:04.950564Z",
     "start_time": "2017-12-28T17:59:22.095228Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "pilot_compute_description = {\n",
    "    \"resource\":\"kinesis://awscloud.com\",\n",
    "    \"number_cores\": 1,\n",
    "    \"type\":\"kinesis\"\n",
    "}\n",
    "kinesis_pilot = pilot.streaming.PilotComputeService.create_pilot(pilot_compute_description)\n",
    "kinesis_pilot.wait()\n",
    "kinesis_details=kinesis_pilot.get_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_handler(event, context):\n",
    "    import numpy as np\n",
    "    import pickle\n",
    "    import sklearn.cluster\n",
    "    import boto3\n",
    "    import sys\n",
    "    import traceback\n",
    "    import base64\n",
    "    import time\n",
    "    #print(\"Lambda Function called\")\n",
    "    for record in event['Records']:\n",
    "        try:\n",
    "            #print(str(record))\n",
    "            start = time.time()\n",
    "            payload=base64.b64decode(record[\"kinesis\"][\"data\"])\n",
    "            #print(\"Payload:\" + str(payload))\n",
    "            data=pickle.loads(payload)\n",
    "            num_points=data.shape[0]\n",
    "            num_dim=data.shape[1]\n",
    "            #print(str(record[\"kinesis\"].keys())) \n",
    "            broker_time = record[\"kinesis\"]['approximateArrivalTimestamp']\n",
    "            #print(str(broker_time))\n",
    "            #print(\"Decoded payload: \" + str(data))\n",
    "            kmeans_model = sklearn.cluster.MiniBatchKMeans(n_clusters=2)\n",
    "            kmeans_model = kmeans_model.partial_fit(data)\n",
    "            end = time.time()\n",
    "            #print(\"Centers: \" + str(kmeans_model.cluster_centers_))\n",
    "            print(\"Context Information:\", context.aws_request_id, context.log_group_name, context.log_stream_name )\n",
    "            print(\"Measurement, Request ID, Log Group, Log Stream, Cores,Number Points, Number Dimensions, Processing Time, Latency\")\n",
    "            print(\"LambdaKMeans, %s, %s, %s, 1, %d, %d, %.5f, %.5f\"%(context.aws_request_id, \n",
    "                                                                context.log_group_name, \n",
    "                                                                context.log_stream_name,\n",
    "                                                                num_points,\n",
    "                                                                num_dim,\n",
    "                                                                (end-start),\n",
    "                                                                end-broker_time\n",
    "                                                               ))\n",
    "        except: \n",
    "            print(\"Error sending message\")\n",
    "            exc_type, exc_value, exc_traceback = sys.exc_info()\n",
    "            print(\"*** print_tb: \")\n",
    "            traceback.print_tb(exc_traceback, limit=1, file=sys.stdout)\n",
    "            print(\"*** print_exception: \")\n",
    "\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pilot_compute_description = {\n",
    "    \"resource\":\"kinesis://awscloud.com\",\n",
    "    \"number_cores\": 1,\n",
    "    \"lambda_input_data\": kinesis_pilot.get_id(),\n",
    "    \"lambda_function\": lambda_handler,\n",
    "    \"lambda_layer\": os.path.join(\"../layers\", \"sklearn.zip\"),\n",
    "    \"type\":\"lambda\"\n",
    "}\n",
    "lambda_pilot = pilot.streaming.PilotComputeService.create_pilot(pilot_compute_description)\n",
    "lambda_pilot.wait()\n",
    "lambda_pilot.get_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiniApp Data Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce some Test Data for K-Means\n",
    "Produce some more data for tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miniapp=mass.kafka.MiniApp(\n",
    "                            dask_scheduler=None,\n",
    "                            resource_url=kinesis_details[\"master_url\"],\n",
    "                            broker_service=\"kinesis\",\n",
    "                            number_parallel_tasks=1,\n",
    "                            number_clusters=3,\n",
    "                            number_points_per_cluster=1000,\n",
    "                            number_points_per_message=1000,\n",
    "                            number_messages=1,\n",
    "                            number_dim=3,\n",
    "                            number_produces=100,\n",
    "                            number_partitions=1,\n",
    "                            topic_name=\"test\",\n",
    "                            application_type=\"kmeans\"\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miniapp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lambda_pilot.cancel()\n",
    "kinesis_pilot.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for manual receiving messages from Kinesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.setup_default_session(profile_name='dev')\n",
    "kinesis_client = boto3.client('kinesis', region_name='us-east-1')\n",
    "stream_name = kinesis_details[\"master_url\"].split(\"/\")[1]\n",
    "print(\"Stream Name: %s\"%stream_name)\n",
    "stream = kinesis_client.describe_stream(StreamName=stream_name)['StreamDescription']\n",
    "\n",
    "messages = []\n",
    "for shard in stream['Shards']:\n",
    "    print(\"### %s - %s\"%(stream_name, shard['ShardId']))\n",
    "    shard_iterator = kinesis_client.get_shard_iterator(\n",
    "        StreamName=stream_name,\n",
    "        ShardId=shard['ShardId'],\n",
    "        ShardIteratorType='AT_TIMESTAMP',  #'TRIM_HORIZON'|'LATEST'\n",
    "        Timestamp=datetime.datetime.utcnow() - datetime.timedelta(minutes=30)\n",
    "    )['ShardIterator']\n",
    "\n",
    "    out = kinesis_client.get_records(ShardIterator=shard_iterator, Limit=1000)\n",
    "    if out[\"Records\"]:\n",
    "        for record in out[\"Records\"]:\n",
    "            #data = json.loads()\n",
    "            messages.append(record[\"Data\"])\n",
    "    else:\n",
    "        print(out)\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "m=pickle.loads(messages[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for manual sending messages to Kinesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kinesis_client = boto3.client('kinesis', region_name='us-east-1')\n",
    "put_response = kinesis_client.put_record(\n",
    "                        StreamName=kinesis_pilot.get_id().split(\"/\")[1],\n",
    "                        Data=\"Hello World\",\n",
    "                        PartitionKey=\"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kinesis_event={\n",
    "  \"Records\": [\n",
    "    {\n",
    "      \"kinesis\": {\n",
    "        \"partitionKey\": \"partitionKey-03\",\n",
    "        \"kinesisSchemaVersion\": \"1.0\",\n",
    "        \"data\": messages[-1],\n",
    "        \"sequenceNumber\": \"49545115243490985018280067714973144582180062593244200961\",\n",
    "        \"approximateArrivalTimestamp\": 1428537600\n",
    "      },\n",
    "      \"eventSource\": \"aws:kinesis\",\n",
    "      \"eventID\": \"shardId-000000000000:49545115243490985018280067714973144582180062593244200961\",\n",
    "      \"invokeIdentityArn\": \"arn:aws:iam::EXAMPLE\",\n",
    "      \"eventVersion\": \"1.0\",\n",
    "      \"eventName\": \"aws:kinesis:record\",\n",
    "      \"eventSourceARN\": \"arn:aws:kinesis:EXAMPLE\",\n",
    "      \"awsRegion\": \"us-east-1\"\n",
    "    }\n",
    "  ]}\n",
    "lambda_handler(kinesis_event, None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
