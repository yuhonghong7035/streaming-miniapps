{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Producer Mini-App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# System Libraries\n",
    "import sys, os\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import pykafka\n",
    "import mass.kafka\n",
    "import math\n",
    " \n",
    "\n",
    "## logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "logging.getLogger(\"py4j\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"tornado.application\").setLevel(logging.CRITICAL)\n",
    "logging.getLogger(\"distributed.utils\").setLevel(logging.CRITICAL)\n",
    "\n",
    "\n",
    "# Pilot-Streaming\n",
    "import pilot.streaming\n",
    "import uuid \n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmpwagvnwha\n",
      "Submission of Job Command: ssh login1.wrangler.tacc.utexas.edu sbatch  tmpwagvnwha\n",
      "Cleanup: ssh login1.wrangler.tacc.utexas.edu rm tmpwagvnwha\n",
      "**** Job: 106391 State : Running\n",
      "/tmp/tmpftavft67\n",
      "Submission of Job Command: ssh login1.wrangler.tacc.utexas.edu sbatch  tmpftavft67\n",
      "Cleanup: ssh login1.wrangler.tacc.utexas.edu rm tmpftavft67\n",
      "**** Job: 106392 State : Running\n",
      "look for configs in: /work/01131/tg804093/wrangler/work/kafka-520a8812-02e9-11e9-9bc5-57e42458a317/config\n",
      "['broker-0']\n",
      "Kafka Config: /work/01131/tg804093/wrangler/work/kafka-520a8812-02e9-11e9-9bc5-57e42458a317/config (Tue Dec 18 11:21:37 2018)\n",
      "{'broker.id': '0', 'listeners': 'PLAINTEXT://c251-121:9092', 'zookeeper.connect': 'c251-121:2181', 'zookeeper.connection.timeout.ms': '6000'}\n",
      "look for configs in: /work/01131/tg804093/wrangler/work/kafka-520a8812-02e9-11e9-9bc5-57e42458a317/config\n",
      "['broker-0']\n",
      "Kafka Config: /work/01131/tg804093/wrangler/work/kafka-520a8812-02e9-11e9-9bc5-57e42458a317/config (Tue Dec 18 11:21:37 2018)\n",
      "{'broker.id': '0', 'listeners': 'PLAINTEXT://c251-121:9092', 'zookeeper.connect': 'c251-121:2181', 'zookeeper.connection.timeout.ms': '6000'}\n",
      "Run Application: synthetic, Number Messages: 48, Message Size: 1024\n",
      "Number Messages: 48\n",
      "MASS - Produce to Kafka\n",
      "Use Dask Distributed\n",
      "{'type': 'Scheduler', 'id': 'Scheduler-12707cdd-d805-43c2-a166-7fd82151a93b', 'address': 'tcp://129.114.58.113:8786', 'services': {'bokeh': 8787}, 'workers': {'tcp://129.114.58.113:44842': {'type': 'Worker', 'id': 'tcp://129.114.58.113:44842', 'host': '129.114.58.113', 'resources': {}, 'local_directory': '/home/01131/tg804093/worker-d5vje_q2', 'name': 'tcp://129.114.58.113:44842', 'ncores': 48, 'memory_limit': 134775570432, 'last_seen': 1545153834.929599, 'services': {'nanny': 41492, 'bokeh': 40259}, 'metrics': {'cpu': 4.0, 'memory': 86880256, 'time': 1545153834.428889, 'read_bytes': 83901.24962771153, 'write_bytes': 83901.24962771153, 'num_fds': 25, 'executing': 0, 'in_memory': 0, 'ready': 0, 'in_flight': 0}}}}\n",
      "Kafka/Kinesis: c251-121:2181, Dask: tcp://129.114.58.113:8786, Number Dask Nodes: 1,  Number Parallel Producers: 1\n",
      "/home/01131/tg804093/work/kafka_2.11-2.1.0/bin/kafka-topics.sh --delete --zookeeper c251-121:2181 --topic test-b20761ea-02e9-11e9-9bc5-57e42458a317\n",
      "/home/01131/tg804093/work/kafka_2.11-2.1.0/bin/kafka-topics.sh --create --zookeeper c251-121:2181 --replication-factor 1 --partitions 8 --topic test-b20761ea-02e9-11e9-9bc5-57e42458a317\n",
      "/home/01131/tg804093/work/kafka_2.11-2.1.0/bin/kafka-topics.sh --describe --zookeeper c251-121:2181 --topic test-b20761ea-02e9-11e9-9bc5-57e42458a317\n",
      "Application: synthetic, Broker: kafka, Number Partitions: 8, Generate Block ID: 0/0\n",
      "Waiting for Dask Tasks to complete - Set Timeout to: 1800\n",
      "End Produce via Dask\n",
      "Number: 0, Number Parallel Tasks: 1, Runtime: 247.07223439216614\n",
      "Run Application: synthetic, Number Messages: 48, Message Size: 1024\n",
      "Number Messages: 48\n",
      "MASS - Produce to Kafka\n",
      "Use Dask Distributed\n",
      "{'type': 'Scheduler', 'id': 'Scheduler-12707cdd-d805-43c2-a166-7fd82151a93b', 'address': 'tcp://129.114.58.113:8786', 'services': {'bokeh': 8787}, 'workers': {'tcp://129.114.58.113:44842': {'type': 'Worker', 'id': 'tcp://129.114.58.113:44842', 'host': '129.114.58.113', 'resources': {}, 'local_directory': '/home/01131/tg804093/worker-d5vje_q2', 'name': 'tcp://129.114.58.113:44842', 'ncores': 48, 'memory_limit': 134775570432, 'last_seen': 1545154085.4308813, 'services': {'nanny': 41492, 'bokeh': 40259}, 'metrics': {'cpu': 2.0, 'memory': 122732544, 'time': 1545154084.9293766, 'read_bytes': 157919.38244203362, 'write_bytes': 157919.38244203362, 'num_fds': 27, 'executing': 0, 'in_memory': 0, 'ready': 0, 'in_flight': 0}}}}\n",
      "Kafka/Kinesis: c251-121:2181, Dask: tcp://129.114.58.113:8786, Number Dask Nodes: 1,  Number Parallel Producers: 2\n",
      "/home/01131/tg804093/work/kafka_2.11-2.1.0/bin/kafka-topics.sh --delete --zookeeper c251-121:2181 --topic test-4741cd04-02ea-11e9-9bc5-57e42458a317\n",
      "/home/01131/tg804093/work/kafka_2.11-2.1.0/bin/kafka-topics.sh --create --zookeeper c251-121:2181 --replication-factor 1 --partitions 8 --topic test-4741cd04-02ea-11e9-9bc5-57e42458a317\n",
      "/home/01131/tg804093/work/kafka_2.11-2.1.0/bin/kafka-topics.sh --describe --zookeeper c251-121:2181 --topic test-4741cd04-02ea-11e9-9bc5-57e42458a317\n",
      "Application: synthetic, Broker: kafka, Number Partitions: 8, Generate Block ID: 0/1\n",
      "Application: synthetic, Broker: kafka, Number Partitions: 8, Generate Block ID: 1/1\n",
      "Waiting for Dask Tasks to complete - Set Timeout to: 1800\n",
      "End Produce via Dask\n",
      "Number: 0, Number Parallel Tasks: 2, Runtime: 125.1191520690918\n",
      "Run Application: synthetic, Number Messages: 48, Message Size: 1024\n",
      "Number Messages: 48\n",
      "MASS - Produce to Kafka\n",
      "Use Dask Distributed\n",
      "{'type': 'Scheduler', 'id': 'Scheduler-12707cdd-d805-43c2-a166-7fd82151a93b', 'address': 'tcp://129.114.58.113:8786', 'services': {'bokeh': 8787}, 'workers': {'tcp://129.114.58.113:44842': {'type': 'Worker', 'id': 'tcp://129.114.58.113:44842', 'host': '129.114.58.113', 'resources': {}, 'local_directory': '/home/01131/tg804093/worker-d5vje_q2', 'name': 'tcp://129.114.58.113:44842', 'ncores': 48, 'memory_limit': 134775570432, 'last_seen': 1545154218.42978, 'services': {'nanny': 41492, 'bokeh': 40259}, 'metrics': {'cpu': 2.0, 'memory': 130666496, 'time': 1545154217.9296963, 'read_bytes': 214333.4500311432, 'write_bytes': 214657.50967728396, 'num_fds': 29, 'executing': 0, 'in_memory': 0, 'ready': 0, 'in_flight': 0}}}}\n",
      "Kafka/Kinesis: c251-121:2181, Dask: tcp://129.114.58.113:8786, Number Dask Nodes: 1,  Number Parallel Producers: 4\n",
      "/home/01131/tg804093/work/kafka_2.11-2.1.0/bin/kafka-topics.sh --delete --zookeeper c251-121:2181 --topic test-96898672-02ea-11e9-9bc5-57e42458a317\n",
      "/home/01131/tg804093/work/kafka_2.11-2.1.0/bin/kafka-topics.sh --create --zookeeper c251-121:2181 --replication-factor 1 --partitions 8 --topic test-96898672-02ea-11e9-9bc5-57e42458a317\n",
      "/home/01131/tg804093/work/kafka_2.11-2.1.0/bin/kafka-topics.sh --describe --zookeeper c251-121:2181 --topic test-96898672-02ea-11e9-9bc5-57e42458a317\n",
      "Application: synthetic, Broker: kafka, Number Partitions: 8, Generate Block ID: 0/3\n",
      "Application: synthetic, Broker: kafka, Number Partitions: 8, Generate Block ID: 1/3\n",
      "Application: synthetic, Broker: kafka, Number Partitions: 8, Generate Block ID: 2/3\n",
      "Application: synthetic, Broker: kafka, Number Partitions: 8, Generate Block ID: 3/3\n",
      "Waiting for Dask Tasks to complete - Set Timeout to: 1800\n",
      "End Produce via Dask\n",
      "Number: 0, Number Parallel Tasks: 4, Runtime: 65.11639451980591\n",
      "Run Application: synthetic, Number Messages: 48, Message Size: 1024\n",
      "Number Messages: 48\n",
      "MASS - Produce to Kafka\n",
      "Use Dask Distributed\n",
      "{'type': 'Scheduler', 'id': 'Scheduler-12707cdd-d805-43c2-a166-7fd82151a93b', 'address': 'tcp://129.114.58.113:8786', 'services': {'bokeh': 8787}, 'workers': {'tcp://129.114.58.113:44842': {'type': 'Worker', 'id': 'tcp://129.114.58.113:44842', 'host': '129.114.58.113', 'resources': {}, 'local_directory': '/home/01131/tg804093/worker-d5vje_q2', 'name': 'tcp://129.114.58.113:44842', 'ncores': 48, 'memory_limit': 134775570432, 'last_seen': 1545154288.4304738, 'services': {'nanny': 41492, 'bokeh': 40259}, 'metrics': {'cpu': 2.0, 'memory': 142905344, 'time': 1545154287.9290314, 'read_bytes': 246397.17793206818, 'write_bytes': 246701.50545588203, 'num_fds': 37, 'executing': 4, 'in_memory': 0, 'ready': 0, 'in_flight': 0}}}}\n",
      "Kafka/Kinesis: c251-121:2181, Dask: tcp://129.114.58.113:8786, Number Dask Nodes: 1,  Number Parallel Producers: 8\n",
      "/home/01131/tg804093/work/kafka_2.11-2.1.0/bin/kafka-topics.sh --delete --zookeeper c251-121:2181 --topic test-c0853214-02ea-11e9-9bc5-57e42458a317\n",
      "/home/01131/tg804093/work/kafka_2.11-2.1.0/bin/kafka-topics.sh --create --zookeeper c251-121:2181 --replication-factor 1 --partitions 8 --topic test-c0853214-02ea-11e9-9bc5-57e42458a317\n",
      "/home/01131/tg804093/work/kafka_2.11-2.1.0/bin/kafka-topics.sh --describe --zookeeper c251-121:2181 --topic test-c0853214-02ea-11e9-9bc5-57e42458a317\n",
      "Application: synthetic, Broker: kafka, Number Partitions: 8, Generate Block ID: 0/7\n",
      "Application: synthetic, Broker: kafka, Number Partitions: 8, Generate Block ID: 1/7\n",
      "Application: synthetic, Broker: kafka, Number Partitions: 8, Generate Block ID: 2/7\n",
      "Application: synthetic, Broker: kafka, Number Partitions: 8, Generate Block ID: 3/7\n",
      "Application: synthetic, Broker: kafka, Number Partitions: 8, Generate Block ID: 4/7\n",
      "Application: synthetic, Broker: kafka, Number Partitions: 8, Generate Block ID: 5/7\n",
      "Application: synthetic, Broker: kafka, Number Partitions: 8, Generate Block ID: 6/7\n",
      "Application: synthetic, Broker: kafka, Number Partitions: 8, Generate Block ID: 7/7\n",
      "Waiting for Dask Tasks to complete - Set Timeout to: 1800\n",
      "End Produce via Dask\n",
      "Number: 0, Number Parallel Tasks: 8, Runtime: 35.14267086982727\n",
      "/tmp/tmpg48q07md\n",
      "Submission of Job Command: ssh login1.wrangler.tacc.utexas.edu sbatch  tmpg48q07md\n",
      "Cleanup: ssh login1.wrangler.tacc.utexas.edu rm tmpg48q07md\n",
      "**** Job: 106407 State : Queue\n",
      "look for configs in: /work/01131/tg804093/wrangler/work/kafka-da38998a-02ea-11e9-9bc5-57e42458a317/config\n",
      "['broker-0']\n",
      "Kafka Config: /work/01131/tg804093/wrangler/work/kafka-da38998a-02ea-11e9-9bc5-57e42458a317/config (Tue Dec 18 11:32:42 2018)\n",
      "{'broker.id': '0', 'listeners': 'PLAINTEXT://c251-121:9092', 'zookeeper.connect': 'c251-121:2181', 'zookeeper.connection.timeout.ms': '6000'}\n",
      "look for configs in: /work/01131/tg804093/wrangler/work/kafka-da38998a-02ea-11e9-9bc5-57e42458a317/config\n",
      "['broker-0']\n",
      "Kafka Config: /work/01131/tg804093/wrangler/work/kafka-da38998a-02ea-11e9-9bc5-57e42458a317/config (Tue Dec 18 11:32:42 2018)\n",
      "{'broker.id': '0', 'listeners': 'PLAINTEXT://c251-121:9092', 'zookeeper.connect': 'c251-121:2181', 'zookeeper.connection.timeout.ms': '6000'}\n",
      "Run Application: synthetic, Number Messages: 48, Message Size: 1024\n",
      "Number Messages: 48\n",
      "MASS - Produce to Kafka\n",
      "Use Dask Distributed\n",
      "{'type': 'Scheduler', 'id': 'Scheduler-12707cdd-d805-43c2-a166-7fd82151a93b', 'address': 'tcp://129.114.58.113:8786', 'services': {'bokeh': 8787}, 'workers': {'tcp://129.114.58.113:44842': {'type': 'Worker', 'id': 'tcp://129.114.58.113:44842', 'host': '129.114.58.113', 'resources': {}, 'local_directory': '/home/01131/tg804093/worker-d5vje_q2', 'name': 'tcp://129.114.58.113:44842', 'ncores': 48, 'memory_limit': 134775570432, 'last_seen': 1545154497.4303627, 'services': {'nanny': 41492, 'bokeh': 40259}, 'metrics': {'cpu': 0.0, 'memory': 166264832, 'time': 1545154496.9287794, 'read_bytes': 322332.9795499753, 'write_bytes': 324115.34056095046, 'num_fds': 39, 'executing': 0, 'in_memory': 0, 'ready': 0, 'in_flight': 0}}}}\n",
      "Kafka/Kinesis: c251-121:2181, Dask: tcp://129.114.58.113:8786, Number Dask Nodes: 1,  Number Parallel Producers: 1\n",
      "/home/01131/tg804093/work/kafka_2.11-2.1.0/bin/kafka-topics.sh --delete --zookeeper c251-121:2181 --topic test-3d005ddc-02eb-11e9-9bc5-57e42458a317\n",
      "/home/01131/tg804093/work/kafka_2.11-2.1.0/bin/kafka-topics.sh --create --zookeeper c251-121:2181 --replication-factor 1 --partitions 16 --topic test-3d005ddc-02eb-11e9-9bc5-57e42458a317\n",
      "/home/01131/tg804093/work/kafka_2.11-2.1.0/bin/kafka-topics.sh --describe --zookeeper c251-121:2181 --topic test-3d005ddc-02eb-11e9-9bc5-57e42458a317\n",
      "Application: synthetic, Broker: kafka, Number Partitions: 16, Generate Block ID: 0/0\n",
      "Waiting for Dask Tasks to complete - Set Timeout to: 1800\n",
      "End Produce via Dask\n",
      "Number: 0, Number Parallel Tasks: 1, Runtime: NA\n",
      "Run Application: synthetic, Number Messages: 48, Message Size: 1024\n",
      "Number Messages: 48\n",
      "MASS - Produce to Kafka\n",
      "Use Dask Distributed\n",
      "{'type': 'Scheduler', 'id': 'Scheduler-12707cdd-d805-43c2-a166-7fd82151a93b', 'address': 'tcp://129.114.58.113:8786', 'services': {'bokeh': 8787}, 'workers': {'tcp://129.114.58.113:44842': {'type': 'Worker', 'id': 'tcp://129.114.58.113:44842', 'host': '129.114.58.113', 'resources': {}, 'local_directory': '/home/01131/tg804093/worker-d5vje_q2', 'name': 'tcp://129.114.58.113:44842', 'ncores': 48, 'memory_limit': 134775570432, 'last_seen': 1545154731.9302175, 'services': {'nanny': 41492, 'bokeh': 40259}, 'metrics': {'cpu': 2.0, 'memory': 174309376, 'time': 1545154731.4292197, 'read_bytes': 120105.3583831087, 'write_bytes': 120994.74641653107, 'num_fds': 40, 'executing': 1, 'in_memory': 0, 'ready': 0, 'in_flight': 0}}}}\n",
      "Kafka/Kinesis: c251-121:2181, Dask: tcp://129.114.58.113:8786, Number Dask Nodes: 1,  Number Parallel Producers: 2\n",
      "/home/01131/tg804093/work/kafka_2.11-2.1.0/bin/kafka-topics.sh --delete --zookeeper c251-121:2181 --topic test-c8d84752-02eb-11e9-9bc5-57e42458a317\n",
      "/home/01131/tg804093/work/kafka_2.11-2.1.0/bin/kafka-topics.sh --create --zookeeper c251-121:2181 --replication-factor 1 --partitions 16 --topic test-c8d84752-02eb-11e9-9bc5-57e42458a317\n",
      "/home/01131/tg804093/work/kafka_2.11-2.1.0/bin/kafka-topics.sh --describe --zookeeper c251-121:2181 --topic test-c8d84752-02eb-11e9-9bc5-57e42458a317\n",
      "Application: synthetic, Broker: kafka, Number Partitions: 16, Generate Block ID: 0/1\n",
      "Application: synthetic, Broker: kafka, Number Partitions: 16, Generate Block ID: 1/1\n",
      "Waiting for Dask Tasks to complete - Set Timeout to: 1800\n"
     ]
    }
   ],
   "source": [
    "for num_repeats in range(10):\n",
    "    for num_producer_nodes in [1,2,4]:\n",
    "        \n",
    "        dask_pilot_description = {\n",
    "                 \"resource\":\"slurm+ssh://login1.wrangler.tacc.utexas.edu\",\n",
    "                 \"working_directory\": os.path.join('/work/01131/tg804093/wrangler/', \"work\"),\n",
    "                 \"number_cores\": 48*num_producer_nodes,\n",
    "                 \"project\": \"TG-MCB090174\",\n",
    "                 \"queue\": \"normal\",\n",
    "                 \"walltime\": 300,\n",
    "                 \"type\":\"dask\"\n",
    "            }\n",
    "        dask_pilot = pilot.streaming.PilotComputeService.create_pilot(dask_pilot_description)\n",
    "        dask_pilot.wait()\n",
    "        dask_details=dask_pilot.get_details()\n",
    "        #dask_details={'master_url': 'tcp://c251-101:8786'}\n",
    "        \n",
    "        for num_broker_nodes in [1,2,4]: #,2,4\n",
    "            for num_partitions_per_node in [8,16, 32]:\n",
    "                number_partitions=num_broker_nodes*num_partitions_per_node\n",
    "                #for application in [\"kmeans-5000\", \"kmeansstatic-5000\", \"kmeansstatic-10000\", \"kmeansstatic-20000\", \"light\"]:\n",
    "                for application_scenario in [\"synthetic-1024\"]:    #\"kmeans-5000\",\n",
    "                    kafka_pilot_description1 = {\n",
    "                        \"resource\":\"slurm+ssh://login1.wrangler.tacc.utexas.edu\",\n",
    "                        \"working_directory\": os.path.join('/work/01131/tg804093/wrangler/', \"work\"),\n",
    "                        \"number_cores\": 48*num_broker_nodes,\n",
    "                        \"project\": \"TG-MCB090174\",\n",
    "                        \"queue\": \"normal\",\n",
    "                        \"walltime\": 300,\n",
    "                        \"type\":\"kafka\"\n",
    "                    }\n",
    "                    kafka_pilot = pilot.streaming.PilotComputeService.create_pilot(kafka_pilot_description1)\n",
    "                    kafka_pilot.wait()\n",
    "                    kafka_details = kafka_pilot.get_details()\n",
    "                    \n",
    "                    time.sleep(120)\n",
    "                    for npt_exponent in range(0, math.floor(math.log2(number_partitions))+1): # number_partitions to 2^6=64 [1,2,4,8,16,32,64]:\n",
    "                        number_parallel_tasks=2**npt_exponent\n",
    "                        number_parallel_tasks = num_producer_nodes*number_parallel_tasks\n",
    "                        number_points_per_message = 5000\n",
    "                        message_size = -1\n",
    "\n",
    "                        if application_scenario.startswith(\"kmeans\"):\n",
    "                            number_points_per_message = int(application_scenario.split(\"-\")[1])\n",
    "                            application = application_scenario.split(\"-\")[0]\n",
    "                        elif application_scenario.startswith(\"synthetic\"):\n",
    "                            application = application_scenario.split(\"-\")[0]\n",
    "                            message_size = application_scenario.split(\"-\")[1]\n",
    "                        else:\n",
    "                            application = application_scenario\n",
    "                            number_points_per_message = 1\n",
    "                        \n",
    "                        number_messages=48\n",
    "                        print(\"Run Application: %s, Number Messages: %d, Message Size: %s\"%(application, number_messages, message_size))\n",
    "                        run_id = str(uuid.uuid1())\n",
    "                        miniapp=mass.kafka.MiniApp(\n",
    "                                                     dask_scheduler=dask_details['master_url'],\n",
    "                                                     resource_url=kafka_details[\"master_url\"],\n",
    "                                                     broker_service=\"kafka\",\n",
    "                                                     number_parallel_tasks=number_parallel_tasks,\n",
    "                                                     #number_clusters=10, # kmeans\n",
    "                                                     #number_points_per_cluster=10000, # kmeans\n",
    "                                                     #number_points_per_message=number_points_per_message, # kmeans\n",
    "                                                     #number_dim=3, # kmeans\n",
    "                                                     number_messages=number_messages, # light, synthetic\n",
    "                                                     message_size = message_size,\n",
    "                                                     number_produces=1,\n",
    "                                                     number_partitions=num_broker_nodes*num_partitions_per_node,\n",
    "                                                     topic_name=\"test-\"+run_id,\n",
    "                                                     application_type = application\n",
    "                                                    )\n",
    "                        miniapp.run()\n",
    "                    try:\n",
    "                        kafka_pilot.cancel()\n",
    "                        os.system(\"/home/01131/tg804093/clean_kafka.sh\")\n",
    "                    except:\n",
    "                        pass\n",
    "        try:\n",
    "            dask_pilot.cancel()\n",
    "            os.system(\"/home/01131/tg804093/clean.sh\")\n",
    "            time.sleep(120)\n",
    "        except: \n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_pilot.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import distributed\n",
    "c=distributed.Client(\"tcp://c251-101:8786\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.scheduler_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inc(x):\n",
    "    import socket\n",
    "    return socket.gethostname()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.delayed import delayed\n",
    "t = delayed(inc)(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Mini App Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Kafka Broker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pykafka.KafkaClient(zookeeper_hosts=kafka_details[\"master_url\"])\n",
    "topic = client.topics['test']\n",
    "producer = topic.get_sync_producer()\n",
    "consumer = topic.get_simple_consumer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "number_total_points = 0\n",
    "number_dimensions = 0\n",
    "for i in range(100):\n",
    "    message = consumer.consume(block=False)\n",
    "    if message is not None:\n",
    "        data_np = np.array(ast.literal_eval(message.value))\n",
    "        num_points = data_np.shape[0]\n",
    "        number_dimensions = data_np.shape[1]\n",
    "        count =  count + 1\n",
    "        number_total_points = number_total_points + num_points\n",
    "    #print \"Consumed message: %d, Number Points: %d, Number Dimensions: %d\"%\\\n",
    "    #        (count, num_points, number_dimensions)   \n",
    "        \n",
    "print(\"Total Messages: %d, Total Points: %d, Number Dimensions: %d\"%(count, number_total_points, number_dimensions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
